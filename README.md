# ECE60131_Project

## Preliminaries and Causal Assumptions
- The underlying latent causal process is a dynamic Bayesian network (DBN) $G = (V,E)$ over a set of $K$ causal variables.
  - Each node $i \in V$ is associated with a causal variable $C_i$, which can be scalar or vector valued.
  - Each edge $(i,j)\in E$ represents a causal replation from $C_i$ to $C_j$: $C_i \rightarrow C_j$, where $C_i$ is a parent of $C_j$ and $pa_G (C_i)$ are all parents of $C_i$ in $G.$
- The DBN is first-order Markov, stationary, and without instantaneous effects.
  - We denote the set of all causal variables at time $t$ as $C^t = (C^t_1, \ldots, C^t_K)$, where $C^{t}$ inherits all edges from its components $C_{i}$ for $i \in \[ 1..K\]$ without introducing cycles.
  - In this setting the structure of the graph is time-invariant, i.e., $pa_G(C^t_i) = pa_G(C^1_i)$ for any $t \in \[ 1..T \]$.
  - For $t \in \[ 1, \dots , T\]$ and for each causal factor $i \in \[ 1, \dots , K \]$, we can model $C_i = f_i(pa_G (C_i^t), \epsilon_i)$, wehre $pa_G (C_i^t) \subset {C_1^{t-1}, \dots, C_k^{t-1}}.$, where all $\epsilon_{i}$ for $i \in \[ 1..K \]$ are mutually independent noises

- We use a binary intervention vector $I^{t} \in \lbrace 0,1 \rbrace^{K}$ to indicate that a variable $C_{i}^{t}$ in $G$ is intervened upon if and only if $I_{i}^{t} = 1$.
- We consider that the intervention vector components $I_{i}^{t}$ might be confounded by another $I_{j}^{t}$, $i \neq j$, and represent these dependencies with an unobserved regime variable $R^{t}$

- With this, we construct an augmented DAG $G' = (V', E')$, where $V' = \lbrace \lbrace C_i^t \rbrace\^K_{i=1} \cup \lbrace I_i^t \rbrace^K_{i=1} \cup R^t \rbrace^T_{t=1}$
  and $E' = \lbrace \lbrace pa_G(C^t_i) \to C_i^t \rbrace^{K}\_{i=1} \cup \lbrace I_i^t \to C_i^t\rbrace\^K_{i=1}
      \cup \lbrace R^{t} \to I_{i}^{t} \rbrace_{i=1}^{K} \rbrace \_{t=1}^{T}.$

- We say that a distribution $p$ is Markov w.r.t. the augmented DAG $G'$ if it factors as $p(V') = \prod_{j \in V'} p(V_{j} \mid pa_{G'}(V_{j})),$
where $V_{j}$ includes the causal factors $C_{i}^{t}$, the intervention vector components $I_{i}^{t}$, and the regime $R^{t}$. Moreover, we say that $p$ is faithful to a causal graph $G'$, if there are no additional conditional independences to the d-separations one can read from the graph $G'$.

- We will consider \emph{soft} interventions, in which the conditional distribution changes, i.e.,
  $p(C_{i}^{t} \mid pa_G(C_{i}^{t}), I_{i}^{t}=1) \neq p(C_{i}^{t} \mid pa_G(C_{i}^{t}), I_{i}^{t}=0),$
which include as a special case \emph{perfect} interventions $\mathrm{do}(C_{i} = c_{i})$

## Identifiability of minimal Causal Variables

![alt text](https://github.com/phlippe/CITRIS/blob/main/figures/icitris_setup.png)

### TempoRal Intervened Sequences (TRIS)
(we consider data generated by an underlying latent temporal causal process with $K$ \emph{causal factors} $\bigl(C_{1}^{t}, C_{2}^{t}, \ldots, C_{K}^{t}\bigr)_{t=1}^{T}$.)
- At each time step $t$, we observe a high-dimensional observation $X^{T}$ representing a noisy, entangled view of all causal factors.

#### Multidimensional Causal Factors
- We allow them to be potentially multidimensional, i.e., $C_{i} \in \mathcal{D}\_{i}^{M_{i}}$ with $M_{i} \ge 1$ and in practice we let $\mathcal{D}_{i}$ be $\mathbb{R}$ for continuous variables (e.g., spatial position), $\mathbb{Z}$ for discrete variables (e.g., the score of a player) or mixed. 
- We define the causal factor space as $\mathcal{C} = \mathcal{D}\_{1}^{M_{1}} \times \mathcal{D}\_{2}^{M_{2}} \times \cdots \times \mathcal{D}\_{K}^{M_{K}}.$

#### Observation Function
- We define the observation function $h(C_{1}^{t}, C_{2}^{t}, \ldots, C_{K}^{t}, E_{\mathrm{o}}^{t}) = X^{t}$, where $E_{\mathrm{o}}^{t}$ represents any noise independent of the causal factors that influence the observations, and $h : \mathcal{C} \times \mathcal{E} \to \mathcal{X}$ is a function from the causal factor space $\mathcal{C}$ and the space of the noise variables $\mathcal{E}$ to the observation space $\mathcal{X}$.
- We assume that $h$ is bijective, implying that the joint dimensionality of the noise and causal model is limited to the image size.
  (This allows us to identify each causal factor uniquely from observations by learning an approximation of $f$, while disregarding irrelevant features in the observation space.)

#### Availability of Intervention Targets
- We assume that in each time-step some causal factors might (or might not) have been intervened upon and that we have access to the corresponding intervention targets, but not the intervention values.

### Necessary Condition for Disentanglement in TRIS
(In TRIS, we generally cannot disentangle two causal factors if they are always intervened upon jointly, or, on the contrary, if they are never intervened upon.)

\newtheorem{prop}{Proposition}
In TRIS, if two causal factors $C_i$ and $C_j$ have only been jointly intervened on or not at all, then there exists a causal graph in which $C_i$ and $C_j$ cannot be uniquely identified from observations $X$ and intervention targets $I$.
\end{prop}

(Additionally, in TRIS where the latent causal factors may correspond to multidimensional vectors, we cannot even completely reconstruct said factors, when by the nature of the system the provided interventions leave some of the causal factorâ€™s dimensions unaffected. In the next section, we will instead introduce the concept of minimal causal variables to characterize what we can identify instead.)

### Minimal Causal Variables

![alt text](https://github.com/phlippe/CITRIS/blob/main/figures/ball_in_boxes.png)

Over time, the ball can move freely within the box it is currently in, but it can only jump into another box if there is an intervention. The intervention moves the ball to the other box, but keeps the relative position of the ball within the box intact. (While one could define this process by a single causal variable $x$ over time,)It can be described by two causal variables: the relative position within the box $x'$ and the current box $b$. Since only $b$ is affected by the intervention, and we consider causal factors to potentially be multidimensional, we could not identify which causal factor $x'$ belongs to.

(We formalize this intuition as follows.)

Suppose for each causal factor $C_i \in \mathcal{D}\_i^{M_i}$, there exists an invertible map $s_i : \mathcal{D}\_i^{M_i} \to \mathcal{D}\_i^{\mathrm{var}} \times \mathcal{D}\_i^{\mathrm{inv}}$ that splits the domain $\mathcal{D}_i^{M_i}$ of $C_i$ into a part that is variant and a part thatis invariant under intervention. We denote the two parts of this map as
```math
  s_i(C_i^{t})
  = \bigl(s_i^{\mathrm{var}}(C_i^{t}),
          s_i^{\mathrm{inv}}(C_i^{t})\bigr)
\label{eq:split}
```

- The split $s$ must be invertible, so that we can map back and forth between $\mathcal{D}_i^{M_i}$ and $\mathcal{D}_i^{\mathrm{var}} \times \mathcal{D}\_i^{\mathrm{inv}}$ without losing information.
- To be called a split in this setup, $s$ must satisfy
  ```math
s_i^{\mathrm{inv}}(C_i^{t})
  \perp I_i^{t} \mid \mathrm{pa}(C_i^{t}),
  ```
i.e., $s_i^{\mathrm{inv}}(C_i^{t})$ is independent of the intervention variable $I_i^{t}$ given the parents of $C_i^{t}$. Also, both parts of the split must be conditionally independent, i.e.
  ```math
  s_i^{\mathrm{inv}}(C_i^{t})
  \perp s_i^{\mathrm{var}}(C_i^{t})
  \mid \mathrm{pa}(C_i^{t}), I_i^{t}.
  ```
  
This means that $s_i^{\mathrm{var}}(C_i^{t})$ will contain the manipulable, or variable, part of $C_i^{t}$. In contrast, $s_i^{\mathrm{inv}}(C_i^{t})$ is the invariable part of $C_i^{t}$ which is independent of the intervention.

For any causal variable, there may exist multiple possible splits. There is always at least the trivial split where $\mathcal{D}_i^{\mathrm{var}} = \mathcal{D}_i^{M_i}$ is the original domain of $C_i$, and $\mathcal{D}_i^{\mathrm{inv}} = \{0\}$ is the one-element set (no invariant information).

(But not all splits are trivial: For the example in Figure~3, we can split the causal factor $x$ in $s_i^{\mathrm{var}}(x)$ such that the box identifier $b$ is in $s_i^{\mathrm{var}}(x)$ and the relative position in the box $x'$ is in $s_i^{\mathrm{inv}}(x)$. Intuitively, we want to identify the split where $s_i^{\mathrm{var}}$ contains \emph{only} the manipulable information:)

\newtheorem{def}{Definition}
The minimal causal split of a variable $C_i^{t}$ with respect to its intervention variable $I_i^{t}$ is the split $s_i$ which maximizes the information content $H\bigl(s_i^{\mathrm{inv}}(C_i^{t}) \mid \mathrm{pa}(C_i^{t})\bigr)$. Under this split, $s_i^{\mathrm{var}}(C_i^{t})$ is defined as the minimal causal variable and denoted by $s_i^{\mathrm{var}*}(C_i^{t})$.
\end{def}






