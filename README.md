# CITRIS (Causal Identifiability from Temporal Intervened Sequences) + TS-CP^2

Reference Paper: [![CITRIS](assets/citris-banner.png)](https://arxiv.org/abs/2202.03169) ![TS-CP^2](https://arxiv.org/abs/2011.14097) 
Reference Code: [![CITRISVAE](https://github.com/phlippe/CITRIS/tree/main)

## 0. Code
The repository is structured in three main folders:
- experiments contains all utilities for running experiments.
- models contains the code of CITRIS and CITRIS-TSCP^2.
- data_generation contains all utilities for creating the dataset.

### 0.1.1. Environment
```bash
conda env create -f environment.yml
conda activate citris
```

### Running experiments
For running an experiment, the following steps need to be taken:
1. Train a Causal Encoder (experiments/train_causal_encoder.py) on the dataset. This is the supervised CNN used for the triplet evaluation for CITRIS.
2. Train the respective model (experiments/train_vae.py) where the causal encoder, and eventually the autoencoder, are passed as arguments.

See the additional README in the folder experiments/ for further details and examples for running experiments.

## 1. Motivation / Core Question for the project

CITRIS assumes a temporally evolving causal process with interventions, but it doesn’t explicitly model abrupt regime changes / change points.

Project question:
1. **Real-world setting (no labels):** In realistic sequential data, we usually don’t have access to ground-truth intervention targets \(I^t\).  
   Can we build a **CITRIS-like model that works without intervention labels** by inferring **soft intervention/change-point gates** \(g_t \in (0,1)^K\) directly from the latent time series?

2. **Change-point awareness:** If we add a TS-CP²-style temporal contrastive module (history–future CPC), do we obtain representations that are more sensitive to **regime shifts / abrupt distribution changes**?

3. **Downstream robustness:** Does this label-free, change-point-aware variant improve (a) recovery of meaningful causal factors and (b) robustness under distribution shifts, compared to vanilla CITRIS that relies on labeled intervention targets?

## 2. Method
### 2.1. CITRIS-VAE
#### 2.1.1. Set-up: Temporal Intervened Sequences (TRIS)
- **The underlying latent causal process is a dynamic Bayesian network (DBN) $G = (V,E)$ over a set of $K$ causal variables.**
  - Each node $i \in V$ is associated with a causal variable $C_i$, which can be scalar or vector valued.
  - Each edge $(i,j)\in E$ represents a causal replation from $C_i$ to $C_j$: $C_i \rightarrow C_j$, where $C_i$ is a parent of $C_j$ and $pa_G (C_i)$ are all parents of $C_i$ in $G.$
- **The DBN is first-order Markov, and stationary without instantenous effect**
  - We denote the set of all causal variables at time $t$ as $C^t = (C^t_1, \ldots, C^t_K)$, where $C^{t}$ inherits all edges from its components $C_{i}$ for $i \in \[ 1..K\]$ without introducing cycles.
  - In this setting the structure of the graph is time-invariant, i.e., $pa_G(C^t_i) = pa_G(C^1_i)$ for any $t \in \[ 1..T \]$.
  - For $t \in \[ 1, \dots , T\]$ and for each causal factor $i \in \[ 1, \dots , K \]$, we can model $C_i = f_i(pa_G (C_i^t), \epsilon_i)$, wehre $pa_G (C_i^t) \subset {C_1^{t-1}, \dots, C_k^{t-1}}.$, where all $\epsilon_{i}$ for $i \in \[ 1..K \]$ are mutually independent noises
- **We use a binary intervention vector $I^{t} \in \lbrace 0,1 \rbrace^{K}$ to indicate that a variable $C_{i}^{t}$ in $G$ is intervened upon if and only if $I_{i}^{t} = 1$.**
- We consider that the intervention vector components $I_{i}^{t}$ might be confounded by another $I_{j}^{t}$, $i \neq j$, and represent these dependencies with an unobserved regime variable $R^{t}$

- We say that a distribution $p$ is Markov w.r.t. the augmented DAG $G'$ if it factors as $p(V') = \prod_{j \in V'} p(V_{j} \mid pa_{G'}(V_{j})),$
where $V_{j}$ includes the causal factors $C_{i}^{t}$, the intervention vector components $I_{i}^{t}$, and the regime $R^{t}$. Moreover, we say that $p$ is faithful to a causal graph $G'$, if there are no additional conditional independences to the d-separations one can read from the graph $G'$.

- **We will consider soft interventions, in which the conditional distribution changes**, i.e., $p(C_{i}^{t} \mid pa_G(C_{i}^{t}), I_{i}^{t}=1) \neq p(C_{i}^{t} \mid pa_G(C_{i}^{t}), I_{i}^{t}=0),$ which include as a special case perfect interventions $\mathrm{do}(C_{i} = c_{i})$

<img width="569" height="475" alt="image" src="https://github.com/user-attachments/assets/cec6fd88-0b93-48da-99c5-99212250f731" />

**we consider data generated by an underlying latent temporal causal process with $K$ causal factors $\bigl(C_{1}^{t}, C_{2}^{t}, \ldots, C_{K}^{t}\bigr)_{t=1}^{T}$. At each time step $t$, we observe a high-dimensional observation $X^{T}$ representing a noisy, entangled view of all causal factors.**

- **Multidimensional Causal Factors**
  - We allow them to be potentially multidimensional, i.e., $C_{i} \in \mathcal{D}\_{i}^{M_{i}}$ with $M_{i} \ge 1$ and in practice we let $\mathcal{D}_{i}$ be $\mathbb{R}$ for continuous variables (e.g., spatial position), $\mathbb{Z}$ for discrete variables (e.g., the score of a player) or mixed. 
  - We define the causal factor space as $\mathcal{C} = \mathcal{D}\_{1}^{M_{1}} \times \mathcal{D}\_{2}^{M_{2}} \times \cdots \times \mathcal{D}\_{K}^{M_{K}}.$

- **Observation Function**
  - We define the observation function $h(C_{1}^{t}, C_{2}^{t}, \ldots, C_{K}^{t}, E_{\mathrm{o}}^{t}) = X^{t}$, where $E_{\mathrm{o}}^{t}$ represents any noise independent of the causal factors that influence the observations, and $h : \mathcal{C} \times \mathcal{E} \to \mathcal{X}$ is a function from the causal factor space $\mathcal{C}$ and the space of the noise variables $\mathcal{E}$ to the observation space $\mathcal{X}$.
  - We assume that $h$ is bijective, implying that the joint dimensionality of the noise and causal model is limited to the image size.
  (This allows us to identify each causal factor uniquely from observations by learning an approximation of $f$, while disregarding irrelevant features in the observation space.)

- **Availability of Intervention Targets**
- We assume that in each time-step some causal factors might (or might not) have been intervened upon and that we have access to the corresponding intervention targets, but not the intervention values.

#### 2.1.2. Key idea: Minimal causal variables
- Necessary Condition for Disentanglement in TRIS
**In TRIS, we generally cannot disentangle two causal factors if they are always intervened upon jointly, or, on the contrary, if they are never intervened upon.**

\newtheorem{prop}{Proposition}
In TRIS, if two causal factors $C_i$ and $C_j$ have only been jointly intervened on or not at all, then there exists a causal graph in which $C_i$ and $C_j$ cannot be uniquely identified from observations $X$ and intervention targets $I$.
\end{prop}

<img width="612" height="234" alt="image" src="https://github.com/user-attachments/assets/4d76ac46-9229-48b3-8db9-faf4058930c3" />

Interventions may not affect all dimensions of a causal variable
=> Minimal causal variables: the part of a causal variable whose mechanism i sstrictly influeneced by the provided interventions. 

We formalize this intuition as follows.

Suppose for each causal factor $C_i \in \mathcal{D}\_i^{M_i}$, there exists an invertible map $s_i : \mathcal{D}\_i^{M_i} \to \mathcal{D}\_i^{\mathrm{var}} \times \mathcal{D}\_i^{\mathrm{inv}}$ that splits the domain $\mathcal{D}_i^{M_i}$ of $C_i$ into a part that is variant and a part thatis invariant under intervention. We denote the two parts of this map as
```math
  s_i(C_i^{t})
  = \bigl(s_i^{\mathrm{var}}(C_i^{t}),
          s_i^{\mathrm{inv}}(C_i^{t})\bigr)
```

- The split $s$ must be invertible, so that we can map back and forth between $\mathcal{D}_i^{M_i}$ and $\mathcal{D}_i^{\mathrm{var}} \times \mathcal{D}\_i^{\mathrm{inv}}$ without losing information.
- To be called a split in this setup, $s$ must satisfy
```math
  s_i^{\mathrm{inv}}(C_i^{t}) \perp I_i^t \mid pa(C_i^t),
```
  i.e., $s_i^{\mathrm{inv}}(C_i^{t})$ is independent of the intervention variable $I_i^{t}$ given the parents of $C_i^{t}$. Also, both parts of the split must be conditionally independent, i.e.
  ```math
  s_i^{\mathrm{inv}}(C_i^{t}) \perp s_i^{\mathrm{var}}(C_i^{t}) \mid pa(C_i^{t}), I_i^{t}.
  ```
  
This means that $s_i^{\mathrm{var}}(C_i^{t})$ will contain the manipulable, or variable, part of $C_i^{t}$. In contrast, $s_i^{\mathrm{inv}}(C_i^{t})$ is the invariable part of $C_i^{t}$ which is independent of the intervention.

For any causal variable, there may exist multiple possible splits. There is always at least the trivial split where $\mathcal{D}_i^{\mathrm{var}} = \mathcal{D}_i^{M_i}$ is the original domain of $C_i$, and $\mathcal{D}_i^{\mathrm{inv}} = \{0\}$ is the one-element set (no invariant information).

(But not all splits are trivial: For the example in Figure~3, we can split the causal factor $x$ in $s_i^{\mathrm{var}}(x)$ such that the box identifier $b$ is in $s_i^{\mathrm{var}}(x)$ and the relative position in the box $x'$ is in $s_i^{\mathrm{inv}}(x)$. 

Intuitively, we want to identify the split where $s_i^{\mathrm{var}}$ contains only the manipulable information:)

- **Definition**
The minimal causal split of a variable $C_i^{t}$ with respect to its intervention variable $I_i^{t}$ is the split $s_i$ which maximizes the information content $H\bigl(s_i^{\mathrm{inv}}(C_i^{t}) \mid \mathrm{pa}(C_i^{t})\bigr)$. Under this split, $s_i^{\mathrm{var}}(C_i^{t})$ is defined as the minimal causal variable and denoted by $s_i^{\mathrm{var}*}(C_i^{t})$.

- $H$ denotes the entropy in the discrete case, or the limiting density of discrete points (LDDP) which measures information content of a continuous variable and is invariant under the change of variables induced by the map $s$.
(Intuitively, this ensures that only the information which truly depends on the intervention is represented in $s_i^{\mathrm{var}}(C_i)$. The definition of the minimal causal split depends on the characteristics of the provided intervention. In our previous example, when an intervention on $x$ would also change the internal box position, the minimal causal variable would contain the full causal factor $x$. Our goal becomes to identify these minimal causal variables.)

- If the interventions are soft, the minimal causal variable, $s_i^{\mathrm{var}}(C_i)$, has as parents the subset of $\mathrm{pa}(C_i)$, whose relation to $C_i$ is influenced by the intervention.
(For instance, consider a three-dimensional causal variable, of which each dimension has a different set of parents. If an intervention only affects the first dimension, $s_i^{\mathrm{var}}(C_i)$ has the same parents as the first dimension, and $s_i^{\mathrm{inv}}(C_i)$ the same parents as the last two dimensions.
- For perfect interventions, the intervention-invariant part, $s_i^{\mathrm{inv}}(C_i)$, has no parents since all temporal dependencies are influenced by the intervention. Thus, in this case, the parents of $s_i^{\mathrm{var}}(C_i)$ are the same as of the true causal variable, $\mathrm{pa}(C_i)$.


#### 2.1.3. Learning Minimal Causal Variables

- We consider a dataset $\mathcal{D}$ of tuples $\{x^{t}, x^{t+1}, I^{t+1}\}$ where $x^{t}, x^{t+1} \in \mathbb{R}^{N}$ represent the observations at time step $t$ and $t+1$ respectively, and $I^{t+1}$ describes the targets of the interventions performed on $C^{t+1}$. 
- We consider a latent space $\mathcal{Z}$ larger than the latent causal factor space $\mathcal{C}$, i.e., $\mathcal{Z} \subseteq \mathbb{R}^{M}$, $M \ge \dim(\mathcal{E}) + \sum_{i=1}^{K} M_{i} = \dim(\mathcal{E}) + \dim(\mathcal{C})$. In this latent space, we aim to disentangle the causal factors. Since we may not know the exact dimensions $M_{1},\ldots,M_{K}$, we overestimate its size in the latent space $\mathcal{Z}$.
- Our goal is to approximate the inverse of the observation function $h$ by learning two components.
  - First, we learn an invertible mapping from observations to latent space, $g_{\theta} : \mathcal{X} \rightarrow \mathcal{Z}$.
  - Second, we learn an assignment function $\psi : [1..M] \rightarrow [0..K]$ that maps each dimension of $\mathcal{Z}$ to a causal factor.
  - In addition to the $K$ causal factors, we use $\psi(j) = 0$, $j \in [1..M]$ to indicate that the latent dimension $z_{j}$ does not belong to any minimal causal variable. Instead, those dimensions might model $s_{i}^{\mathrm{inv}}(C_{i})$ for some causal factor $C_{i}$; or the observation noise $E_{\mathrm{o}}^{t}$.
  - Finally, we denote the set of latent variables that $\psi$ assigns to the causal factor $C_{i}$ with $z_{\psi_{i}} = \{ z_{j} \mid j \in [1..M], \psi(j) = i \}$.
- To enforce a disentanglement of causal factors, we model a prior distribution in latent space, $p_{\phi}(z^{t+1} \mid z^{t}, I^{t+1})$, with $x^{t}, x^{t+1} \in \mathcal{X}$, $z^{t}, z^{t+1} \in \mathcal{Z}$, $z^{t} = g_{\theta}(x^{t})$, $z^{t+1} = g_{\theta}(x^{t+1})$. This transition prior enforces a disentanglement by conditioning each latent variable on exactly one of the intervention targets:
```math
p_{\phi}(z^{t+1} \mid z^{t}, I^{t+1})
= \prod_{i=0}^{K}
  p_{\phi}\bigl(z^{t+1}_{\psi_{i}} \mid z^{t}, I^{t+1}_{i}\bigr),
```
where $I^{t+1}\_{0} = 0$. Then, the objective of the model is to maximize the likelihood:
```math
p_{\phi,\theta}(x^{t+1} \mid x^{t}, I^{t+1})
  = \left\lvert
      \frac{\partial g_{\theta}(x^{t+1})}{\partial x^{t+1}}
    \right\vert
    p_{\phi}(z^{t+1} \mid z^{t}, I^{t+1}).
```

(Under the assumptions stated in Section~3.1, we can prove the following identifiability result for this setup)
- **Theorem**
  Suppose that $\phi^{\ast}$, $\theta^{\ast}$ and $\psi^{\ast}$ are the parameters that, under the constraint of maximizing the likelihood $p_{\phi,\theta}(x^{t+1} \mid x^{t}, I^{t+1})$, maximize the information content of $p_{\phi}(z^{t+1}_{\psi_{0}} \mid z^{t})$. Then, with sufficient latent dimensions, the model $\phi^{\ast}$, $\theta^{\ast}$, $\psi^{\ast}$ learns a latent structure where $z^{t+1}_{\psi_{i}}$ models the minimal causal variable of $C_{i}$ if $C_{i}^{t+1} \not\!\perp I_{i}^{t+1} \mid C^{t}, I_{j}^{t+1}$ for any $i \neq j$. All remaining information is modeled in $z_{\psi_{0}}$.

It relies on $I_{i}^{t+1}$ not being a deterministic function of any other intervention target. A sufficient condition for this is the interventions being independent of each other, or single-target interventions with observational data. Finding the minimal variables intuitively means that the latent variables $z_{\psi_{i}}$ model only the information of $C_{i}$ which strictly depends on the intervention target $I_{i}^{t+1}$, thus defining causal variables by their intervention dependency. Going back to the example of the $x$ position of the ball in Figure~3, we would model the box identifier in $z_{\psi_{1}}$ if $C_{1} = x$, while the internal box position is modeled in $z_{\psi_{0}}$. We empirically verify the learned split for this example in Appendix~D.3. Nonetheless, one can always ensure that for any definition of the causal process, $z_{\psi_{i}}$ only contains information of causal variable $C_{i}$ of that process, and no other causal variable.

#### 2.1.4. Causal Identifiability from Temporal Intervened Sequences (CITRIS-VAE)
<img width="678" height="403" alt="image" src="https://github.com/user-attachments/assets/c49565bd-d152-4072-a30b-e26c19575c15" />

- We use a Variational Autoencoder (VAE) with
  - encoder $\(q_\theta(z^{t+1}\mid x^{t+1})\)$,
  - decoder $\(p_\theta(x^{t+1}\mid z^{t+1})\)$,
  - transition prior $\(p_\phi(z^{t+1}\mid z^{t}, I^{t+1})\)$ that models temporal dynamics under interventions $\(I^{t+1}\)$.

- The training objective is the Evidence Lower Bound (ELBO)
```math
    \mathcal{L}_{\text{ELBO}}
    = - \mathbb{E}\_{z^{t+1}}\!\lbrace \log p_\theta\!\bigl(x^{t+1} \mid z^{t+1}\bigr) \rbrace \\
    \quad + \mathbb{E}_{z^{t},\psi}\!\lbrace \sum_{i=0}^{K} D_{\mathrm{KL}}\!\left(q_\theta\!\bigl(z_{\psi_i}^{t+1} \mid x^{t+1}\bigr) \,\big\|\, p_\phi\!\bigl(z\_{\psi_i}^{t+1} \mid z^{t}, I_i^{t+1}\bigr) \right) \rbrace.
 ```
  - Intuitively, the ELBO has two parts:
    - Reconstruction term
    $\(- \mathbb{E}\_{z^{t+1}}\[\log p_\theta(x^{t+1}\mid z^{t+1})]\)$: encourages accurate reconstruction of $\(x^{t+1}\)$ from the latent variable $(z^{t+1})$.
    - Regularization term}
    $\(\sum_i D_{\mathrm{KL}}(\cdot\|\cdot)\)$: encourages the approximate posterior $\(q_\theta\)$ to stay close to the transition prior $\(p_\phi\)$, preventing overfitting and encoding temporal causal structure.

- Each latent dimension is assigned to a causal variable via an assignment vector $\(\psi\)$, learned with a Gumbel--Softmax distribution (one categorical distribution per latent dimension). 
- During training, we sample assignments; at inference time, we use an $\(\arg\max\)$ for a deterministic mapping.

- For each causal group of latents $\(z_{\psi_i}^{t+1}\)$, the transition prior $\(p_\phi\)$ is an autoregressive Gaussian model conditioned on $z^{t},\quad I_i^{t+1}, \quad \text{and a masked version of } z^{t+1}$
  where only the dimensions assigned to causal variable $\(i\)$ are active. This yields flexible temporal dynamics while maintaining independence across causal groups.

- A target classifier is trained to predict intervention targets from the latents, modeling
    $p\bigl(I_i^{t+1} \mid z^{t}, z_{\psi_i}^{t+1}\bigr) \quad\text{for } i \in \{0,\dots,K\}.$
  Its gradients are applied only to the corresponding latent group \(z_{\psi_i}^{t+1}\), encouraging each group to carry information about its intended causal variable \(C_i\).

 For targets $\(I_j^{t+1}\)$ with $\(j \neq i\)$, the label is replaced by the marginal $\(p(I_j \mid I_i)\)$, so that these targets cannot be fully identified from the ``wrong'' latent group. This helps disentangle different causal factors in latent space.

- Overall, the ELBO, grouped KL terms, Gumbel--Softmax assignments, autoregressive prior, and target classifier work together so that
  - each subset of latents corresponds to a distinct causal variable, and
  - the full latent space captures all relevant causal information and temporal structure under interventions.


### 2.2. Change-Point-Aware Temporal Contrastive Module (TS-CP^2)
We extend the original CITRIS-VAE with a **temporal window encoder** and a **contrastive objective** to make the latent representation more sensitive to **change points / regime shifts** in the time series.

#### 2.2.1. Temporal window encoder
Let \(z_t\in\mathbb{R}^D\) be the CITRIS latent at time \(t\). We encode windows using a temporal encoder \(f_\psi\) (e.g., 1D CNN / TCN / GRU):

\[
h_t^H=f_\psi(z_{t-L+1:t}),\qquad h_t^F=f_\psi(z_{t+1:t+L})
\]

Positive pairs are \((h_t^H,h_t^F)\); negatives come from other time indices / sequences.

#### 2.2.2. Contrastive Predictive Coding (InfoNCE) loss
We train window embeddings so adjacent windows match and far windows differ:

\[
\mathcal{L}_{\text{CPC}}
= -\sum_{t}
\log \frac{\exp(\mathrm{sim}(h_t^H,h_t^F)/\tau)}
{\sum_k \exp(\mathrm{sim}(h_t^H,h_k^F)/\tau)}
\]

where \(\mathrm{sim}\) is cosine similarity and \(\tau\) is temperature.

#### 2.2.3. Change score from history–future similarity
TS-CP² detects candidate change points by drops in history–future similarity:

\[
s_t=\mathrm{sim}(h_t^H,h_t^F),\quad \bar{s}_t=\mathrm{MA}(s_t),\quad c_t=\bar{s}_t - s_t
\]

Large \(c_t\) suggests a potential change point.

#### 2.2.4. Soft intervention gates (replace missing labels)
We infer continuous “intervention degrees” per causal factor with an MLP:

\[
g_t=\sigma(\mathrm{MLP}_\eta([z_{t-1},z_t,c_t]))\in(0,1)^K,\quad g_1=0
\]

The i-th component \(g_t(i)\) represents the inferred degree of intervention on factor \(i\) at time \(t\).

#### 2.2.5. Gated transition prior (interpolation between dynamics vs intervention)
We replace discrete indicators \(I^{t+1}\) with inferred gates \(g_{t+1}\). For each factor \(i\):

\[
p(z^{t+1}_i\mid z^t,g_{t+1}(i))=
\mathcal{N}\Big((1-g)\mu^{dyn}_i(z^t)+g\,\mu^{int}_i,\ (1-g)\Sigma^{dyn}_i+g\,\Sigma^{int}_i\Big)
\]

This smoothly interpolates between “predictable dynamics” and “externally perturbed jump dynamics.”



#### 2.2.6. Overall objective We combine:
- reconstruction loss \(L_{rec}\),
- temporal KL term \(L_{KL}\) vs the gated transition prior,
- CPC loss \(L_{CPC}\),
- gate sparsity penalty \(L_{gate}=\frac{1}{TK}\sum_{t,i} g_t(i)\) to encourage sparse interventions.

Final objective:

\[
L = L_{rec} + \beta_{KL} L_{KL} + \lambda_{CPC} L_{CPC} + \lambda_{gate} L_{gate}
\]

This is designed to jointly learn causal latents, change-point structure, and soft intervention assignments that replace explicit labels.

## 3. Experiments

### 3.1. Dataset: Ball-in-Boxes
Ball moves within a box; only interventions cause box swaps; within-box x-position is unaffected → highlights “minimal causal variables” intuition.
The Ball-in-Boxes is a simple dataset for showcasing the concept of the minimal causal variables. The system consists of a ball which randomly moves within a box, but only under an intervention can swap between the two boxes. Thereby, the intervention does not affect the x-position in the box. Thus, one can only discover the box assignment as a causal variable, and not whether the inner x-position also belongs to it. The dataset generation for the Ball-in-Boxes dataset is implemented in the file data_generation_ball_in_boxes.py. The image rendering is based on matplotlib. To generate the dataset , you can run 
```bash
python data_generation_ball_in_boxes.py --output_folder ball_in_boxes/
```
, where ball_in_boxes/ is the folder in which all data will be saved in.

### 3.2. Models compared
- **CITRISVAE** (baseline)
- **CITRIS-TSCP²VAE** (ours)

### 3.3. Evaluation Metrics
We evaluate disentanglement / causal alignment using correlation-style metrics (e.g., R² diagonal vs off-diagonal, Spearman diagonal vs off-diagonal).


## 4. Results
### 4.1. SUmmary table (single run)
| Model | R² diag ↑ | R² max off ↓ | ρ diag ↑ | ρ max off ↓ |
|---|---:|---:|---:|---:|
| CITRISVAE | -0.00320 | -0.00331 | 0.00328 | 0.00277 |
| CITRIS-TSCP²VAE | -0.00196 | -0.01042 | -0.00116 | 0.00410 |

In this run, values are near zero for both models; CITRIS-TSCP²VAE does not show a clear improvement at this training scale. This suggests either:
- insufficient training / data scale,
- evaluation mismatch vs the original CITRIS pipeline,
- CPC/gate loss weights need tuning.

## 5. Contribution
- **Real-world problem setting:** Reformulated CITRIS for scenarios where **ground-truth intervention targets** \(I^t\) are **not available**, which is more realistic for real-world sequential data.

- **Change-point-aware representation learning:** Added a **TS-CP² temporal window encoder** and a **CPC/InfoNCE contrastive objective** on CITRIS latents to encourage sensitivity to **regime shifts / abrupt distribution changes**.

- **Label-free intervention inference:** Proposed **soft intervention gates** \(g_t \in (0,1)^K\) inferred from the latent sequence (and a change score), replacing discrete intervention labels with a continuous intervention signal.

- **Gated transition prior:** Designed a **gated prior** that interpolates between “normal dynamics” and “intervention-driven” transitions using \(g_t\), enabling CITRIS-style temporal modeling without labeled interventions.

- **End-to-end implementation + evaluation:** Implemented the full training pipeline and evaluated **CITRISVAE (baseline)** vs **CITRIS-TSCP²VAE (ours)** on Ball-in-Boxes using correlation-based disentanglement/alignment metrics (e.g., diagonal vs off-diagonal R²/Spearman).

## 6. Limitations
- Results shown are from limited training scale and a single reported run; conclusions about improvements are not yet robust.
- The gating mechanism assumes change-score spikes correlate with interventions; this may not hold in more complex dynamics.
- There is an inherent trade-off between reconstruction/forecasting and CPC-based separation; careful tuning of \(\lambda_{CPC}\), \(\lambda_{gate}\), \(\beta_{KL}\) is required.


